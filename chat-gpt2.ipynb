{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-08T08:15:44.423879Z","iopub.execute_input":"2023-06-08T08:15:44.424266Z","iopub.status.idle":"2023-06-08T08:15:44.441293Z","shell.execute_reply.started":"2023-06-08T08:15:44.424235Z","shell.execute_reply":"2023-06-08T08:15:44.440060Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/inputdata/new_data1.json\n/kaggle/input/inputdata/arabic_conversation.json\n/kaggle/input/inputdata/arabic_conversation_simulation.json\n/kaggle/input/inputdata/ChatData.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install rouge\n!pip install pytorch-lamb","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:15:44.460806Z","iopub.execute_input":"2023-06-08T08:15:44.461063Z","iopub.status.idle":"2023-06-08T08:16:17.824434Z","shell.execute_reply.started":"2023-06-08T08:15:44.461041Z","shell.execute_reply":"2023-06-08T08:16:17.823156Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pytorch-lamb in /opt/conda/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (4.64.1)\nRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (2.6)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (1.23.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (21.3)\nRequirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorch-lamb) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorch-lamb) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch-lamb) (2.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX->pytorch-lamb) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch-lamb) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nimport tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport json\nimport random\nfrom rouge import Rouge \nfrom pytorch_lamb import Lamb\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:16:17.827207Z","iopub.execute_input":"2023-06-08T08:16:17.827641Z","iopub.status.idle":"2023-06-08T08:16:23.349978Z","shell.execute_reply.started":"2023-06-08T08:16:17.827574Z","shell.execute_reply":"2023-06-08T08:16:23.348938Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef calculate_rouge(hypothesis, reference):\n    rouge = Rouge()\n    scores = rouge.get_scores(hypothesis, reference)\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:16:23.351606Z","iopub.execute_input":"2023-06-08T08:16:23.351953Z","iopub.status.idle":"2023-06-08T08:16:23.357625Z","shell.execute_reply.started":"2023-06-08T08:16:23.351921Z","shell.execute_reply":"2023-06-08T08:16:23.356444Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(path, model, optim,epochs):\n    chatData = ChatData(path, tokenizer)\n    chatData =  DataLoader(chatData, num_workers=2, batch_size=64)\n    test = (\"<Q>كم تبلغ تكلفة التوصيل<bot>:\")\n    output_referance = \"<Q>كم تبلغ تكلفة التوصيل<bot>:تكلفة التوصيل\"\n    model.train()\n\n    \n\n    print(\"training .... \")\n    \n    for i in tqdm.tqdm(range(epochs)):\n        for X, a,Y in chatData:\n            X = X.to(device)\n            a = a.to(device)\n            Y = Y.to(device)\n            optim.zero_grad()\n            #loss = model(X, attention_mask=a, labels=X).loss\n            losses = model(X, attention_mask=a, labels=Y).loss\n            loss = losses.mean()\n            loss.backward()\n            optim.step()\n        # Save the model after each epoch\n        torch.save(model.state_dict(), f\"model_state_epoch_{i}.pt\")\n\n        # Evaluation...\n        model.eval()\n        with torch.no_grad():\n            output = infer(test)\n            print(output)\n            print(calculate_rouge(output, output_referance))\n        model.train()\n    model.eval()\ndef infer(inp):\n    inp = tokenizer(inp, return_tensors=\"pt\")\n    X = inp[\"input_ids\"].to(device)\n    a = inp[\"attention_mask\"].to(device)\n    output =model.module.generate(X, attention_mask=a,max_new_tokens=50 \n                        ,pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id  \n    ,no_repeat_ngram_size=5\n                           )\n    output = tokenizer.decode(output[0])\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:16:23.360424Z","iopub.execute_input":"2023-06-08T08:16:23.360802Z","iopub.status.idle":"2023-06-08T08:16:23.373200Z","shell.execute_reply.started":"2023-06-08T08:16:23.360752Z","shell.execute_reply":"2023-06-08T08:16:23.372241Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nclass ChatData(Dataset):\n    def __init__(self, path:str, tokenizer):\n        self.data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n        self.X = []\n        self.Y = []\n        tmp = \"\"\n        for i in self.data:\n            for j in i['dialog']:\n                if j['sender'] == \"participant2\":\n                    self.X.append(j['text'])\n                    tmp = j['text']+\"<bot>:\"\n                else:\n                    self.Y.append(tmp+j['text'])\n                    tmp = \"\"\n\n        #combined = list(zip(self.X, self.Y))\n        #random.shuffle(combined)\n\n        #self.X[:], self.Y[:] = zip(*combined)\n\n        self.X = self.X[:15000]\n        self.Y = self.Y[:15000]\n        print(self.Y[0])\n        self.X_encoded = tokenizer(self.X, max_length=40, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n        self.Y_encoded = tokenizer(self.Y, max_length=40, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n\n        self.input_ids = self.X_encoded['input_ids']\n        self.attention_mask = self.X_encoded['attention_mask']\n\n        self.target_ids = self.Y_encoded['input_ids']\n        \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attention_mask[idx], self.target_ids[idx]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:16:23.374544Z","iopub.execute_input":"2023-06-08T08:16:23.375011Z","iopub.status.idle":"2023-06-08T08:16:23.388484Z","shell.execute_reply.started":"2023-06-08T08:16:23.374974Z","shell.execute_reply":"2023-06-08T08:16:23.387803Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = \"aubmindlab/aragpt2-base\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.add_special_tokens({\"pad_token\": \"<pad>\", \n                                \"bos_token\": \"<startofstring>\",\n                                \"eos_token\": \"<endofstring>\"})\n\ntokenizer.add_tokens([\"<bot>:\",\"<prevQ>\",\"<prevA>\",\"<Q>\"])\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = nn.DataParallel(model)\nmodel = model.to(device)\n#optim = Lamb(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.01)\n\noptim = Adam(model.parameters(), lr=1e-3)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:16:23.389575Z","iopub.execute_input":"2023-06-08T08:16:23.390335Z","iopub.status.idle":"2023-06-08T08:16:29.828740Z","shell.execute_reply.started":"2023-06-08T08:16:23.390302Z","shell.execute_reply":"2023-06-08T08:16:29.827818Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}]},{"cell_type":"code","source":"train(\"/kaggle/input/inputdata/new_data1.json\", model, optim,3)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:16:29.830279Z","iopub.execute_input":"2023-06-08T08:16:29.830875Z","iopub.status.idle":"2023-06-08T08:23:31.136089Z","shell.execute_reply.started":"2023-06-08T08:16:29.830839Z","shell.execute_reply":"2023-06-08T08:23:31.135107Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<Q>مرحبًا<bot>:مرحبًا بك في مؤسسة اكسبو شوب! كيف يمكنني مساعدتك؟\ntraining .... \n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n 33%|███▎      | 1/3 [02:15<04:31, 135.67s/it]","output_type":"stream"},{"name":"stdout","text":"<Q> كم تبلغ تكلفة التوصيل <bot>: تبلغ تكلفة التوصيل 20 شيكل فقط <Q> شكرا <bot>: أهلاً أن <bot>: أهلا�<pad>ً بك في مؤسسة اكسبو شوب! ما الذي يمكنني أن أفعله من أجلك؟ <Q> ارغب بالاستفسار عن هاتف. ما\n[{'rouge-1': {'r': 0.6, 'p': 0.10714285714285714, 'f': 0.18181817924701563}, 'rouge-2': {'r': 0.25, 'p': 0.029411764705882353, 'f': 0.05263157706371198}, 'rouge-l': {'r': 0.6, 'p': 0.10714285714285714, 'f': 0.18181817924701563}}]\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 2/3 [04:27<02:13, 133.38s/it]","output_type":"stream"},{"name":"stdout","text":"<Q> كم تبلغ تكلفة التوصيل <bot>: تبلغ تكلفة التوصيل 20 شيكل فقط <Q> شكرا <bot>: كر <bot>:  لهاتف. ما هي المنتجات المتوفره لديكم <prevA> لدينا عرض لهاتف متاحة للبيع. سازودكم  ببعض الموديلات الشهيرة هي \n - هاتف iPhone : شاشة 6.5 بوصة،\n[{'rouge-1': {'r': 0.6, 'p': 0.08823529411764706, 'f': 0.1538461516107824}, 'rouge-2': {'r': 0.25, 'p': 0.02564102564102564, 'f': 0.04651162621957821}, 'rouge-l': {'r': 0.6, 'p': 0.08823529411764706, 'f': 0.1538461516107824}}]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [06:40<00:00, 133.36s/it]","output_type":"stream"},{"name":"stdout","text":"<Q> كم تبلغ تكلفة التوصيل <bot>: تبلغ تكلفة التوصيل 20 شيكل فقط <Q> شكرا <bot>:  أن <bot>:  يمكنني أن أفعله من أجلك؟ <Q> ارغب بالاستفسار عن هاتف. ما هي المنتجات المتوفره لديكم <bot>: أهلاًاليك تفاصيل هاتف. ما هي \n تفاصيل هاتف\n[{'rouge-1': {'r': 0.6, 'p': 0.11538461538461539, 'f': 0.19354838439125913}, 'rouge-2': {'r': 0.25, 'p': 0.029411764705882353, 'f': 0.05263157706371198}, 'rouge-l': {'r': 0.6, 'p': 0.11538461538461539, 'f': 0.19354838439125913}}]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"infer from model : \")\nprevQ = \"\"\nprevA = \"\"\nwhile True:\n  inp = input()\n  if inp == \"-1\":\n    break;\n  \n  inp1 = \"<Q>\"+inp+\"<bot>:\"\n  output = infer(inp)\n  print(output)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T08:28:06.875483Z","iopub.execute_input":"2023-06-08T08:28:06.875845Z","iopub.status.idle":"2023-06-08T08:39:03.397130Z","shell.execute_reply.started":"2023-06-08T08:28:06.875816Z","shell.execute_reply":"2023-06-08T08:39:03.396145Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"infer from model : \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" هل يوجد عروض جديد؟\n"},{"name":"stdout","text":"هل يوجد عروض جديد؟ <prevA> أهلاً صحيح، معالج سداسي النواة، ذاكرة 8 غيغابايت، ذاكرة تخزين 128 غيغابايت، ذاكرة 128 غيغابايت، معالج سد ذاكرة تخزين 128 ذاكرة تخزين 128، ذاكرة تخزين ذاكرة تخزين 128� ذاكرة تخزين 128�\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" سعر منتج\n"},{"name":"stdout","text":"سعر منتج، يوجد توصيل لكل منتجاتنا لجميع المحافظات والتجمعات السكنية وخلال 24 ساعة كحد اقصى <Q> كيف يمكنني أن أفعله من أجلك؟ <Q> ارغب بالاستفسار عن هاتف. ما هي المنتجات المتوفره لديكم <bot>: أهلاًاليك تفاصيل هاتف. ما\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" مرحا\n"},{"name":"stdout","text":"مرحاً <prevA> أهلاً يمكنني أن أفعله من أجلك؟ <Q> ارغب بالاستفسار عن هاتف. ما هي المنتجات المتوفره لديكم <bot>: لدينا عرض لهاتف متاحة للبيع. سازودكم لدينا عرض لهاتف، معالج\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" عرض هاتف\n"},{"name":"stdout","text":"عرض هاتف  Nokia 3310 وهي  \n - هاتف  Nokia 3312: وتبلغ تكلفتة 800 دينار <Q> شو تكلفة التوصيل <bot>: تبلغ تكلفة التوصيل <bot>: تبتبلغ تكلفة التوصيل 20 شيكل فقط <Q> شكرا <bot>: شكرا <bot>: أهلاًأ\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" عرض سماعات\n"},{"name":"stdout","text":"عرض سماعات بلوتوث  Nokia 3310 وهي  \n - هاتف  Nokia 3310: شاشة 9.6 بوصة، معالج سداسي النواة، ذاكرة 16 غيغابايت، ذاكرة تخزين 128، ذاكرة تخزين ذاكرة تخزين 128�أتهلاًاليك تفاصيل\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" -1\n"}]}]}