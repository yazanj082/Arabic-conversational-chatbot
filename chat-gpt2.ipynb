{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-09T20:34:15.729493Z","iopub.execute_input":"2023-06-09T20:34:15.731734Z","iopub.status.idle":"2023-06-09T20:34:15.757340Z","shell.execute_reply.started":"2023-06-09T20:34:15.731703Z","shell.execute_reply":"2023-06-09T20:34:15.756102Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/inputdata/new_data1.json\n/kaggle/input/inputdata/arabic_conversation.json\n/kaggle/input/inputdata/arabic_conversation_simulation.json\n/kaggle/input/inputdata/ChatData.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install rouge\n!pip install pytorch-lamb","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:34:15.759271Z","iopub.execute_input":"2023-06-09T20:34:15.759628Z","iopub.status.idle":"2023-06-09T20:34:54.792846Z","shell.execute_reply.started":"2023-06-09T20:34:15.759597Z","shell.execute_reply":"2023-06-09T20:34:54.791349Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pytorch-lamb\n  Downloading pytorch_lamb-1.0.0-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (4.64.1)\nRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (2.6)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (1.23.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (21.3)\nRequirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorch-lamb) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorch-lamb) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch-lamb) (2.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX->pytorch-lamb) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch-lamb) (1.3.0)\nInstalling collected packages: pytorch-lamb\nSuccessfully installed pytorch-lamb-1.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nimport tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport json\nimport random\nfrom rouge import Rouge \nfrom pytorch_lamb import Lamb\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:34:54.794861Z","iopub.execute_input":"2023-06-09T20:34:54.795251Z","iopub.status.idle":"2023-06-09T20:35:20.094904Z","shell.execute_reply.started":"2023-06-09T20:34:54.795214Z","shell.execute_reply":"2023-06-09T20:35:20.093949Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef calculate_rouge(hypothesis, reference):\n    rouge = Rouge()\n    scores = rouge.get_scores(hypothesis, reference)\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:20.097617Z","iopub.execute_input":"2023-06-09T20:35:20.097990Z","iopub.status.idle":"2023-06-09T20:35:20.102561Z","shell.execute_reply.started":"2023-06-09T20:35:20.097955Z","shell.execute_reply":"2023-06-09T20:35:20.101725Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(path, model, optim,epochs):\n    chatData = ChatData(path, tokenizer)\n    chatData =  DataLoader(chatData, num_workers=2, batch_size=64)\n    test = (\"<Q>كم تبلغ تكلفة التوصيل<bot>:\")\n    output_referance = \"<Q>كم تبلغ تكلفة التوصيل<bot>:تكلفة التوصيل\"\n    model.train()\n\n    \n\n    print(\"training .... \")\n    \n    for i in tqdm.tqdm(range(epochs)):\n        for X, a,Y in chatData:\n            X = X.to(device)\n            a = a.to(device)\n            Y = Y.to(device)\n            optim.zero_grad()\n            #loss = model(X, attention_mask=a, labels=X).loss\n            losses = model(X, attention_mask=a, labels=Y).loss\n            loss = losses.mean()\n            loss.backward()\n            optim.step()\n        # Save the model after each epoch\n        torch.save(model.state_dict(), f\"model_state_epoch_{i}.pt\")\n\n        # Evaluation...\n        model.eval()\n        with torch.no_grad():\n            output = infer(test)\n            print(output)\n            rouge_1_r_sum, rouge_1_p_sum, rouge_1_f_sum = 0, 0, 0\n            rouge_2_r_sum, rouge_2_p_sum, rouge_2_f_sum = 0, 0, 0\n            rouge_l_r_sum, rouge_l_p_sum, rouge_l_f_sum = 0, 0, 0\n\n            for i in range(10000):\n                rouge_scores = calculate_rouge(chatData.X[i], chatData.Y[i])[0]  # assuming this function returns a list similar to your example\n                rouge_1_r_sum += rouge_scores['rouge-1']['r']\n                rouge_1_p_sum += rouge_scores['rouge-1']['p']\n                rouge_1_f_sum += rouge_scores['rouge-1']['f']\n\n                rouge_2_r_sum += rouge_scores['rouge-2']['r']\n                rouge_2_p_sum += rouge_scores['rouge-2']['p']\n                rouge_2_f_sum += rouge_scores['rouge-2']['f']\n\n                rouge_l_r_sum += rouge_scores['rouge-l']['r']\n                rouge_l_p_sum += rouge_scores['rouge-l']['p']\n                rouge_l_f_sum += rouge_scores['rouge-l']['f']\n\n            # print averages\n            print('Average Rouge-1 scores: r:', rouge_1_r_sum/10000, ', p:', rouge_1_p_sum/10000, ', f:', rouge_1_f_sum/10000)\n            print('Average Rouge-2 scores: r:', rouge_2_r_sum/10000, ', p:', rouge_2_p_sum/10000, ', f:', rouge_2_f_sum/10000)\n            print('Average Rouge-L scores: r:', rouge_l_r_sum/10000, ', p:', rouge_l_p_sum/10000, ', f:', rouge_l_f_sum/10000)\n        model.train()\n    model.eval()\ndef infer(inp):\n    inp = tokenizer(inp, return_tensors=\"pt\")\n    X = inp[\"input_ids\"].to(device)\n    a = inp[\"attention_mask\"].to(device)\n    output =model.module.generate(X, attention_mask=a,max_new_tokens=50 \n                        ,pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id  \n    ,no_repeat_ngram_size=5\n                           )\n    output = tokenizer.decode(output[0])\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:20.104105Z","iopub.execute_input":"2023-06-09T20:35:20.104732Z","iopub.status.idle":"2023-06-09T20:35:20.117220Z","shell.execute_reply.started":"2023-06-09T20:35:20.104690Z","shell.execute_reply":"2023-06-09T20:35:20.116328Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nclass ChatData(Dataset):\n    def __init__(self, path:str, tokenizer):\n        self.data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n        self.X = []\n        self.Y = []\n        tmp = \"\"\n        for i in self.data:\n            for j in i['dialog']:\n                if j['sender'] == \"participant2\":\n                    self.X.append(j['text'])\n                    tmp = j['text']+\"<bot>:\"\n                else:\n                    self.Y.append(tmp+j['text'])\n                    tmp = \"\"\n\n        #combined = list(zip(self.X, self.Y))\n        #random.shuffle(combined)\n\n        #self.X[:], self.Y[:] = zip(*combined)\n        print(len(self.X),len(self.Y))\n        self.X = self.X[:10000]\n        self.Y = self.Y[:10000]\n        print(self.Y[0])\n        self.X_encoded = tokenizer(self.X, max_length=40, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n        self.Y_encoded = tokenizer(self.Y, max_length=40, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n\n        self.input_ids = self.X_encoded['input_ids']\n        self.attention_mask = self.X_encoded['attention_mask']\n\n        self.target_ids = self.Y_encoded['input_ids']\n        \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attention_mask[idx], self.target_ids[idx]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:20.118590Z","iopub.execute_input":"2023-06-09T20:35:20.119239Z","iopub.status.idle":"2023-06-09T20:35:20.138050Z","shell.execute_reply.started":"2023-06-09T20:35:20.119196Z","shell.execute_reply":"2023-06-09T20:35:20.137168Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = \"aubmindlab/aragpt2-base\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.add_special_tokens({\"pad_token\": \"<pad>\", \n                                \"bos_token\": \"<startofstring>\",\n                                \"eos_token\": \"<endofstring>\"})\n\ntokenizer.add_tokens([\"<bot>:\",\"<prevQ>\",\"<prevA>\",\"<Q>\"])\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = nn.DataParallel(model)\nmodel = model.to(device)\n#optim = Lamb(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.01)\n\noptim = Adam(model.parameters(), lr=1e-3)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:20.139186Z","iopub.execute_input":"2023-06-09T20:35:20.139476Z","iopub.status.idle":"2023-06-09T20:35:36.699569Z","shell.execute_reply.started":"2023-06-09T20:35:20.139452Z","shell.execute_reply":"2023-06-09T20:35:36.698603Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b2a8792ebe48f29fc2d3b9a11dd5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/1.50M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a050dbdbcb46b6ae32eefc8344ed55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dec381811d747f38d9bb82bd221186a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f0cf0797934bdbb5b58c2a8cc73a06"}},"metadata":{}},{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}]},{"cell_type":"code","source":"train(\"/kaggle/input/inputdata/new_data1.json\", model, optim,3)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:36.700922Z","iopub.execute_input":"2023-06-09T20:35:36.701396Z","iopub.status.idle":"2023-06-09T20:35:36.711199Z","shell.execute_reply.started":"2023-06-09T20:35:36.701355Z","shell.execute_reply":"2023-06-09T20:35:36.705587Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def evaluatetion(input):\n    output_referance = \"<Q>مرحبا<bot>:أهلاً في مؤسسة اكسبو شوب! ما الذي يمكنني أن أفعله من أجلك؟\"\n    output = infer(input)\n    print(output)\n    print(calculate_rouge(output, output_referance))","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:36.712808Z","iopub.execute_input":"2023-06-09T20:35:36.713172Z","iopub.status.idle":"2023-06-09T20:35:37.924873Z","shell.execute_reply.started":"2023-06-09T20:35:36.713137Z","shell.execute_reply":"2023-06-09T20:35:37.923746Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"evaluatetion(\"<Q>مرحبا<bot>:\")\nevaluatetion(\"<prevQ>مرحبا<prevA>أهلاً في مؤسسة اكسبو شوب! ما الذي يمكنني أن أفعله من أجلك؟<Q>\"+\"كم سعر شاشات التلفار\"+\"<bot>:\")\nevaluatetion(\"<prevQ>\"+\"كم سعر شاشات التلفار\"+\"<prevA>\"+\"سعر شاشة سامسونغ 1200\"+\"<Q>\"+\"كم تكلفة التوصيل\"+\"<bot>:\")\n#evaluatetion(\"<prevQ>مرحبا\"+\"<prevQ>\"+\"كم سعر شاشات التلفار\"+\"prevA>أهلاً في مؤسسة اكسبو شوب! ما الذي يمكنني أن أفعله من أجلك؟\"+\"<prevA>\"+\"سعر شاشة سامسونغ 1200\"+\"<Q>\"+\"كم تكلفة التوصيل\"+\"<bot>:\")","metadata":{"execution":{"iopub.status.busy":"2023-06-09T20:35:37.928444Z","iopub.execute_input":"2023-06-09T20:35:37.928944Z","iopub.status.idle":"2023-06-09T20:35:45.161253Z","shell.execute_reply.started":"2023-06-09T20:35:37.928908Z","shell.execute_reply":"2023-06-09T20:35:45.160321Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<Q> مرحبا <bot>:  ، ، ، ، ، مرحبا ، ، ، مرحبا بك أخي الزائر الكريم. يمكنك الاستفادة من محتوى البرامج على وجه الخصوص و يشرفنا تسجيلك في المنتدى : اضغط على الصورةموضوع : رد : : : : :..... : : : :\n[{'rouge-1': {'r': 0.16666666666666666, 'p': 0.08, 'f': 0.10810810372534715}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.08333333333333333, 'p': 0.04, 'f': 0.05405404967129327}}]\n<prevQ> مرحبا <prevA> أهلاً في مؤسسة اكسبو شوب! ما الذي يمكنني أن أفعله من أجلك؟ <Q> كم سعر شاشات التلفار <bot>:  ؟ ؟ ؟ ؟ ؟!!!!! ؟ ؟ ؟ ؟ هل يمكن أن يكون هناك شاشات في العالم ؟ ؟ ؟ ؟<|endoftext|>أهلا وسهلا بك زائرنا الكريم, أنت لم تقم بتسجيل الدخول بعد! يشرفنا أن تقوم بالدخول أو التسجيل إذا رغبت بالمشاركة\n[{'rouge-1': {'r': 0.9166666666666666, 'p': 0.23404255319148937, 'f': 0.37288135269175526}, 'rouge-2': {'r': 0.9090909090909091, 'p': 0.18867924528301888, 'f': 0.3124999971533204}, 'rouge-l': {'r': 0.9166666666666666, 'p': 0.23404255319148937, 'f': 0.37288135269175526}}]\n<prevQ> كم سعر شاشات التلفار <prevA> سعر شاشة سامسونغ 1200 <Q> كم تكلفة التوصيل <bot>:  سعر شاشة سامسونغ 1200 ؟ سعر شاشة سامسونغ 1200...<|endoftext|>أهلا وسهلا بك زائرنا الكريم, أنت لم تقم بتسجيل الدخول بعد! يشرفنا أن تقوم بالدخول أو التسجيل إذا رغبت بالمشاركة في المنتدىأهلا وسهلا بك ضيفنا الكريم ، إذا كانت هذه زيارتك الأولى\n[{'rouge-1': {'r': 0.16666666666666666, 'p': 0.046511627906976744, 'f': 0.07272726931570264}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.08333333333333333, 'p': 0.023255813953488372, 'f': 0.03636363295206644}}]\n","output_type":"stream"}]}]}