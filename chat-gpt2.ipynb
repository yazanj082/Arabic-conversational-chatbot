{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-07T23:05:46.716390Z","iopub.execute_input":"2023-06-07T23:05:46.716735Z","iopub.status.idle":"2023-06-07T23:05:46.742681Z","shell.execute_reply.started":"2023-06-07T23:05:46.716707Z","shell.execute_reply":"2023-06-07T23:05:46.741820Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/inputdata/new_data1.json\n/kaggle/input/inputdata/arabic_conversation.json\n/kaggle/input/inputdata/arabic_conversation_simulation.json\n/kaggle/input/inputdata/ChatData.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install rouge\n!pip install pytorch-lamb","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:05:46.749769Z","iopub.execute_input":"2023-06-07T23:05:46.750069Z","iopub.status.idle":"2023-06-07T23:06:25.050956Z","shell.execute_reply.started":"2023-06-07T23:05:46.750043Z","shell.execute_reply":"2023-06-07T23:06:25.049744Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pytorch-lamb\n  Downloading pytorch_lamb-1.0.0-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (4.64.1)\nRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (2.6)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pytorch-lamb) (0.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-lamb) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (1.23.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (21.3)\nRequirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX->pytorch-lamb) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorch-lamb) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pytorch-lamb) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch-lamb) (2.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX->pytorch-lamb) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pytorch-lamb) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch-lamb) (1.3.0)\nInstalling collected packages: pytorch-lamb\nSuccessfully installed pytorch-lamb-1.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nimport tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport json\nimport random\nfrom rouge import Rouge \nfrom pytorch_lamb import Lamb\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:06:25.055660Z","iopub.execute_input":"2023-06-07T23:06:25.055981Z","iopub.status.idle":"2023-06-07T23:06:49.666013Z","shell.execute_reply.started":"2023-06-07T23:06:25.055949Z","shell.execute_reply":"2023-06-07T23:06:49.664888Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef calculate_rouge(hypothesis, reference):\n    rouge = Rouge()\n    scores = rouge.get_scores(hypothesis, reference)\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:06:49.667328Z","iopub.execute_input":"2023-06-07T23:06:49.668026Z","iopub.status.idle":"2023-06-07T23:06:49.673562Z","shell.execute_reply.started":"2023-06-07T23:06:49.667988Z","shell.execute_reply":"2023-06-07T23:06:49.672579Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(path, model, optim,epochs):\n    chatData = ChatData(path, tokenizer)\n    chatData =  DataLoader(chatData, num_workers=2, batch_size=200)\n    test = (\"<startofstring>\"+\"<Q>مرحبًا<bot>:\")\n    output_referance =infer(test)\n    model.train()\n\n    \n\n    print(\"training .... \")\n    \n    for i in tqdm.tqdm(range(epochs)):\n        for X, a,Y in chatData:\n            X = X.to(device)\n            a = a.to(device)\n            Y = Y.to(device)\n            optim.zero_grad()\n            #loss = model(X, attention_mask=a, labels=X).loss\n            losses = model(X, attention_mask=a, labels=Y).loss\n            loss = losses.mean()\n            loss.backward()\n            optim.step()\n        # Save the model after each epoch\n        torch.save(model.state_dict(), f\"model_state_epoch_{i}.pt\")\n\n        # Evaluation...\n        model.eval()\n        with torch.no_grad():\n            output = infer(test)\n            print(output)\n            print(calculate_rouge(output, output_referance))\n        model.train()\ndef infer(inp):\n    inp = tokenizer(inp, return_tensors=\"pt\")\n    X = inp[\"input_ids\"].to(device)\n    a = inp[\"attention_mask\"].to(device)\n    output =model.module.generate(X, attention_mask=a,max_new_tokens=50 \n                        ,pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id\n                           )\n    output = tokenizer.decode(output[0])\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:06:49.676491Z","iopub.execute_input":"2023-06-07T23:06:49.677389Z","iopub.status.idle":"2023-06-07T23:06:49.689253Z","shell.execute_reply.started":"2023-06-07T23:06:49.677355Z","shell.execute_reply":"2023-06-07T23:06:49.688407Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nclass ChatData(Dataset):\n    def __init__(self, path:str, tokenizer):\n        self.data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n        self.X = []\n        self.Y = []\n        tmp = \"\"\n        for i in self.data:\n            for j in i['dialog']:\n                if j['sender'] == \"participant2\":\n                    self.X.append(\"<startofstring>\"+j['text'])\n                    tmp = \"<startofstring>\"+j['text']+\"<bot>:\"\n                else:\n                    self.Y.append(tmp+j['text']+\"<endofstring>\")\n                    tmp = \"\"\n\n        #combined = list(zip(self.X, self.Y))\n        #random.shuffle(combined)\n\n        #self.X[:], self.Y[:] = zip(*combined)\n\n        self.X = self.X[:10000]\n        self.Y = self.Y[:10000]\n        print(self.Y[0])\n        self.X_encoded = tokenizer(self.X, max_length=40, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n        self.Y_encoded = tokenizer(self.Y, max_length=40, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n\n        self.input_ids = self.X_encoded['input_ids']\n        self.attention_mask = self.X_encoded['attention_mask']\n\n        self.target_ids = self.Y_encoded['input_ids']\n        \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attention_mask[idx], self.target_ids[idx]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:06:49.690748Z","iopub.execute_input":"2023-06-07T23:06:49.691080Z","iopub.status.idle":"2023-06-07T23:06:49.707066Z","shell.execute_reply.started":"2023-06-07T23:06:49.691048Z","shell.execute_reply":"2023-06-07T23:06:49.706192Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = \"aubmindlab/aragpt2-base\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.add_special_tokens({\"pad_token\": \"<pad>\", \n                                \"bos_token\": \"<startofstring>\",\n                                \"eos_token\": \"<endofstring>\"})\n\ntokenizer.add_tokens([\"<bot>:\",\"<prevQ>\",\"<prevA>\",\"<Q>\"])\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = nn.DataParallel(model)\nmodel = model.to(device)\n#optim = Lamb(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.01)\n\noptim = Adam(model.parameters(), lr=1e-3)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:06:49.708195Z","iopub.execute_input":"2023-06-07T23:06:49.709067Z","iopub.status.idle":"2023-06-07T23:07:05.373641Z","shell.execute_reply.started":"2023-06-07T23:06:49.709034Z","shell.execute_reply":"2023-06-07T23:07:05.372648Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7343926128342e59f0f48162fdb1b11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/1.50M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7089f896ee4d21a82fb6d01b4358d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f4c4c1d45d4c43a3ce40b35e4835cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20b7cf42bd73483cae47b761a3ecde59"}},"metadata":{}},{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}]},{"cell_type":"code","source":"train(\"/kaggle/input/inputdata/new_data1.json\", model, optim,10)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T23:07:05.374959Z","iopub.execute_input":"2023-06-07T23:07:05.375521Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"<startofstring><Q>مرحبًا<bot>:مرحبًا بك في مؤسسة اكسبو شوب! كيف يمكنني مساعدتك؟<endofstring>\ntraining .... \n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n 10%|█         | 1/10 [01:08<10:20, 68.94s/it]","output_type":"stream"},{"name":"stdout","text":"<startofstring> <Q> مرحبًا <bot>: مرحبًا بك في مؤسسة اكسبو شوب! كيف يمكنني مساعدتك؟ <prevA> ارغب بالاستفسار عن ساعة ذكية. هل يمكنك مساعدتي؟ <prevA> لدينا عرض <prevA> لدينا عرض <bot>: لدينا عرض <bot>: لدينا عرض <prevA> لد\n[{'rouge-1': {'r': 1.0, 'p': 0.16666666666666666, 'f': 0.2857142832653061}, 'rouge-2': {'r': 1.0, 'p': 0.10714285714285714, 'f': 0.19354838534859523}, 'rouge-l': {'r': 1.0, 'p': 0.16666666666666666, 'f': 0.2857142832653061}}]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"infer from model : \")\nprevQ = \"\"\nprevA = \"\"\nwhile True:\n  inp = input()\n  if inp == \"-1\":\n    break;\n  \n  inp = \"<startofstring>\"+prevQ+prevA+\"<Q>\"+inp+\"<bot>:\"\n  prevQ = \"<prevQ>\"+inp\n  output = infer(inp)\n  prevA = \"<prevA>\"+output\n  prevA.replace(\"<bot>:\",\"\")\n  print(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}